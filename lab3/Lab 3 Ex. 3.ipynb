{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubcYWZW_A2ya"
   },
   "source": [
    "# Lab 3 Exercise 3\n",
    "## Binary Classification\n",
    "\n",
    "We are given a dataset that consists of biological features of a person and whether or not they are a smoker.\n",
    "\n",
    "There are *22 descriptive features* and *1 target column* in the dataset as described in the Table below. You are tasked with creating a predictive model to predict the column \"SMK_stat_type_cd\", which specifies smoker/non-smoker status of the person. You are expected to use classification methods that was shown in the previous exercises.\n",
    "\n",
    "\n",
    "\n",
    "|      Column      |                                 Description                                 |\n",
    "|:----------------:|:---------------------------------------------------------------------------:|\n",
    "| identified_gender              | male, female                                                                |\n",
    "| age              | round up to 5 years                                                         |\n",
    "| height           | round up to 5 cm[cm]                                                        |\n",
    "| weight           | [kg]                                                                        |\n",
    "| sight_left       | eyesight(left)                                                              |\n",
    "| sight_right      | eyesight(right)                                                             |\n",
    "| hear_left        | hearing left, 1(normal), 2(abnormal)                                        |\n",
    "| hear_right       | hearing right, 1(normal), 2(abnormal)                                       |\n",
    "| SBP              | Systolic blood pressure[mmHg]                                               |\n",
    "| DBP              | Diastolic blood pressure[mmHg]                                              |\n",
    "| BLDS             | BLDS or FSG(fasting blood glucose)[mg/dL]                                   |\n",
    "| tot_chole        | total cholesterol[mg/dL]                                                    |\n",
    "| HDL_chole        | HDL cholesterol[mg/dL]                                                      |\n",
    "| LDL_chole        | LDL cholesterol[mg/dL]                                                      |\n",
    "| triglyceride     | triglyceride[mg/dL]                                                         |\n",
    "| hemoglobin       | hemoglobin[g/dL]                                                            |\n",
    "| urine_protein    | protein in urine, 1(-), 2(+/-), 3(+1), 4(+2), 5(+3), 6(+4)                  |\n",
    "| serum_creatinine | serum(blood) creatinine[mg/dL]                                              |\n",
    "| SGOT_AST         | SGOT(Glutamate-oxaloacetate transaminase) AST(Aspartate transaminase)[IU/L] |\n",
    "| SGOT_ALT         | ALT(Alanine transaminase)[IU/L]                                             |\n",
    "| gamma_GTP        | y-glutamyl transpeptidase[IU/L]                                             |\n",
    "| SMK_stat_type_cd **(Target)** | Smoking state, 0(never), 1(active smoker)                      |\n",
    "\n",
    "\n",
    "### The stages of this problem can be decomposed as follows:\n",
    "1. Data Preparation\n",
    "* Ensure data is in correct format (numerical and not string)\n",
    "* Normalize the data for better convergence (optional)\n",
    "* Split the data into train/test subsets\n",
    "\n",
    "2. Model Selection\n",
    "* Instanciate models and fit on training data\n",
    "* Evaluate model performance on testing data\n",
    "* Select model with best performance\n",
    "\n",
    "3. Submit model\n",
    "* Your model will be evaluated on data that is kept separate from training/testing data\n",
    "* The predictions from your model will be uploaded to the course server where it will be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/MyDrive/4c16-labs/code/lab-03/\n",
    "!unzip -o data.zip \n",
    "!echo 'data/*' > .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEzBRbM3A2yj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRKrdqgdA2ym"
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "# The data is supplied as \".csv\" format\n",
    "# There are 23 columns in csv file, with 22 columns being features and 1 column being the target\n",
    "\n",
    "# The csv file can be read into as a dataframe using the pandas library\n",
    "DataFrame = pd.read_csv('data/data.csv')\n",
    "\n",
    "# Shuffle the data\n",
    "DataFrame = DataFrame.sample(frac=1)\n",
    "\n",
    "# Visualize the first 5 rows of the imported dataframe\n",
    "display(DataFrame.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIjUfMuJA2yn"
   },
   "outputs": [],
   "source": [
    "# The column \"identified_gender\" contains non-numeric data. This cannot be used as is and needs to be converted to numerical representations\n",
    "# We can encode the identified gender to a numerical representation by letting \"female\" == 0, and \"male\" == 1.\n",
    "# This can be done manually by using conditional statements on the dataframe, but luckily for us there is a simpler method\n",
    "# We can use the built in LabelEncoder function of sklearn to do this\n",
    "\n",
    "LabelEncoder = sklearn.preprocessing.LabelEncoder()\n",
    "LabelEncoder.fit(DataFrame['identified_gender'])\n",
    "DataFrame['identified_gender'] = LabelEncoder.transform(DataFrame['identified_gender'])\n",
    "\n",
    "# Label encoder sorts the input column of data in alphabetical order, and then assigns a numerical value to each unique entry\n",
    "# This results in 'female' being mapped to 0, 'male' being mapped to 1\n",
    "display(DataFrame.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwBzWS-IA2yo"
   },
   "outputs": [],
   "source": [
    "# We should now separate the input features from the target feature and store them as different variables\n",
    "# We do this by slicing what columns of data we want from the dataframe\n",
    "# Let's first see the columns available to us by printing DataFrame.columns\n",
    "print(DataFrame.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZ1Abm_yA2yp"
   },
   "outputs": [],
   "source": [
    "# The column titled \"SMK_stat_type_cd\" is our target, and all remaining variables are our input features.\n",
    "features_columns = DataFrame.columns[:-1]\n",
    "target_column = DataFrame.columns[-1:]\n",
    "\n",
    "DataFrame_X = DataFrame[features_columns]   # Selects only Input features\n",
    "DataFrame_Y = DataFrame[target_column]      # Selects only Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0unCh_ZAA2yq"
   },
   "outputs": [],
   "source": [
    "# Split Data into Train/Test split\n",
    "# Change the variable \"test_frac\" to reflect the percentage/fraction of test data in the resulting split\n",
    "test_frac = 0.15\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(DataFrame_X, DataFrame_Y, test_size=test_frac)\n",
    "print(f\"Number of rows for Training:\\t{Train_X.shape[0]}\\nNumber of rows for Testing:\\t{Test_X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-6vXZSQA2yq"
   },
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "# Construct a dictionary of prediction models to compare\n",
    "# Uncomment the below dictionary and insert as many prediction models as you like.\n",
    "# You may have used binary classification models in previous exercises\n",
    "# You may also have to import these modules/libraries to be able to use them\n",
    "\n",
    "# Import more classes to make things simple\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "PredictionModels = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=20000),  # Increase the max_iter for convergence\n",
    "    'K-NN Classification': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'MLP (Neural Network)': MLPClassifier(max_iter=20000)  # Increase the max_iter for convergence\n",
    "}\n",
    "\n",
    "models = list(PredictionModels.keys())\n",
    "\n",
    "print(models)\n",
    "print(PredictionModels)\n",
    "\n",
    "print(\"Fitting models, this may take a while\")\n",
    "for model_name, model in PredictionModels.items():\n",
    "    # This loop goes through the models in the variable \"PredictionModels\"\n",
    "    # Complete the below code block to fit to the model to training data \"Train_X, Train_Y\"\n",
    "    # Peform predictions on the fitted model on the Train set and Test set\n",
    "    # compute f1 score\n",
    "    model.fit(Train_X, Train_Y.values.ravel())\n",
    "\n",
    "    # Make predictions on the training and test sets\n",
    "    predictions_train = model.predict(Train_X)\n",
    "    predictions_test = model.predict(Test_X)\n",
    "\n",
    "    # Compute the F1 score for both the training and test predictions\n",
    "    f1_train = f1_score(Train_Y, predictions_train)\n",
    "    f1_test = f1_score(Test_Y, predictions_test)\n",
    "\n",
    "    print(f\"F1 Score for {model_name} on training data: {f1_train:.3f}\")\n",
    "    print(f\"F1 Score for {model_name} on test data: {f1_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUCCz779A2ys"
   },
   "outputs": [],
   "source": [
    "# Select the model with best f1 score and write down the\n",
    "# corresponding 'key' value from the 'PredictionModels' variable\n",
    "# Eg if Logistic Regression is chosen then: chosen_model = 'Logistic Regression'\n",
    "chosen_model = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mh3WeQk3A2ys"
   },
   "outputs": [],
   "source": [
    "# DO NOT EDIT.\n",
    "# Generate predictions using \"chosen_model\" and save to file\n",
    "\n",
    "backend_features = pd.read_csv('data/validation.csv')\n",
    "backend_features['identified_gender'] = LabelEncoder.transform(backend_features['identified_gender'])\n",
    "backend_preds = PredictionModels[chosen_model].predict(backend_features)\n",
    "np.savez_compressed('lab3_ex3_preds', lab3_model=backend_preds)\n",
    "\n",
    "# Remember to push your changes to the git server for marking!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NPEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
