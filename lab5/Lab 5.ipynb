{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tTQ7onq7slQq",
    "outputId": "bb7f2809-63a4-40fe-acc7-7fe709adb2bc",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### 4C16 Lab 5 - Convolutional Neural Nets for Image Classification.\n",
    "# see handout-06\n",
    "# https://frcs.github.io/4C16-LectureNotes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElVXHGnUv506"
   },
   "outputs": [],
   "source": [
    "# Note: the training will run significantly faster if you run your notebook as a GPU instance.\n",
    "# to change to GPU mode, you need to go in the colab menu to Runtime>Change runtime type\n",
    "# then select \"hardware accelerator\" to GPU.\n",
    "# This will restart your instance (obviously), so everytime you do this you'll need to\n",
    "# start your again from the start of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dy4u9RfUslzi",
    "outputId": "606efe86-1709-447c-9b11-adf53dc97003"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/MyDrive/4c16-labs/code/lab-05/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGbKHYwEslQs"
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import datasets\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import PReLU, LeakyReLU, Conv2D, MaxPool2D, Lambda\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import pickle\n",
    "import sklearn as skl\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxW3vODDslQt"
   },
   "outputs": [],
   "source": [
    "# Define some useful functions\n",
    "class PlotLossAccuracy(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.acc = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(int(self.i))\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('accuracy'))\n",
    "        self.val_acc.append(logs.get('val_accuracy'))\n",
    "        \n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.plot([1, 2])\n",
    "        plt.subplot(121) \n",
    "        plt.plot(self.x, self.losses, label=\"train loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"validation loss\")\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Model Loss')\n",
    "        plt.legend()\n",
    "        plt.subplot(122)         \n",
    "        plt.plot(self.x, self.acc, label=\"training accuracy\")\n",
    "        plt.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
    "        plt.legend()\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.show();\n",
    "        \n",
    "def save_model_to_disk():    \n",
    "    # save model and weights (don't change the filenames)\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to model.json and weights to model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RptPR_p7slQt",
    "outputId": "eddb649c-7fff-4812-ca0f-47cfafb2a5f9"
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!curl --create-dirs -o /home/tcd/data/cifar10-dataset.pkl https://tcddeeplearning.blob.core.windows.net/deeplearning202324/cifar10-dataset.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "t60nbfR_slQu",
    "outputId": "52e04e42-6eaa-4e27-def6-3455f5ca793c"
   },
   "outputs": [],
   "source": [
    "print('loading the dataset...')\n",
    "\n",
    "pkl_file = open('/home/tcd/data/cifar10-dataset.pkl', 'rb')\n",
    "dataset = pickle.load(pkl_file)\n",
    "\n",
    "print('loaded.')\n",
    "\n",
    "print('let\\'s look at some of the pictures and their ground truth labels:')\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot([3, 3])\n",
    "\n",
    "X = dataset['X'].astype('float32')/255\n",
    "Y = dataset['Y'].astype('float32')\n",
    "Y = tf.keras.utils.to_categorical(Y)\n",
    "\n",
    "for i in range(0,9):\n",
    "    # pictures are 32x32x3 (width=32, height=32, 3 colour channels)\n",
    "    pic = X[i]\n",
    "\n",
    "    # Y[i] returns an array of zeros and with Y[i][classid] = 1\n",
    "    # for instance  Y[i] = [ 0 0 0 0 0 1 0 0 0 0] => classid=5 \n",
    "    #          and  Y[i] = [ 1 0 0 0 0 0 0 0 0 0] => classid=0\n",
    "    # we can get the classid by using the argmax function on the vector Y[i]\n",
    "    classid = Y[i].argmax(-1)\n",
    "\n",
    "    # getting back the name of the label for that classid\n",
    "    classname = dataset['labels'][classid]\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(pic)\n",
    "    plt.title('label: {}'.format(classname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpjSDuP2slQu"
   },
   "outputs": [],
   "source": [
    "# let's split data between validation set and training set\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = skl.model_selection.train_test_split(X, Y, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vppw4dotslQv",
    "outputId": "efa16ac8-e7b8-46c5-b84d-4a329718bcaf"
   },
   "outputs": [],
   "source": [
    "# The model below contains 2 hidden layers with 64 nodes each. \n",
    "# The activation functions for these 2 layers is the ReLU\n",
    "# The network ends with a 10 nodes layer with softmax activation\n",
    "# The first 2 hidden layers transform the original features into \n",
    "# a new feature vector of size 64.\n",
    "# The last layer essentially does the classification using multonomial regression\n",
    "# based on these new features. \n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "inputs = keras.layers.Input(shape=(32, 32, 3))\n",
    "x = inputs\n",
    "\n",
    "# First convolutional block\n",
    "x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Second convolutional block\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Third convolutional block\n",
    "x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Flatten and put through dense layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = keras.models.Model(inputs=inputs, outputs=predictions)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "if model.count_params() > 4500000:\n",
    "    raise Exception(\"Your model is unnecessarily complex, scale down!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "toLFo18qslQv",
    "outputId": "287c4b12-8be1-4b94-af8a-c0630fbbc480"
   },
   "outputs": [],
   "source": [
    "# Note that you can evaluate this cell repeatedly to push the training of your model further.\n",
    "# You might want to reduce the value of 'num_epochs' if each evaluation starts to take too long.\n",
    "\n",
    "num_epochs = 60\n",
    "\n",
    "# Create an instance of our callback functions class, to plot our loss function and accuracy with each epoch.\n",
    "pltCallBack = PlotLossAccuracy()\n",
    "\n",
    "# Run the training.\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=1024, epochs=num_epochs, \n",
    "          validation_data=(X_validation, Y_validation), \n",
    "          callbacks=[pltCallBack])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rb6o20NslQw",
    "outputId": "d005953f-9ea4-4ef0-a9c9-395189fd042a"
   },
   "outputs": [],
   "source": [
    "# write model to model.json and weights to model.h5 for submission\n",
    "\n",
    "save_model_to_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "OXBctzM-slQw"
   },
   "outputs": [],
   "source": [
    "# you can now commit and push and submit lab for assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Drgzs3aNslQw"
   },
   "outputs": [],
   "source": [
    "# Question: using a combination of dense and convolutional layers, achieve 80%\n",
    "#           or more accuracy on the server's test set.\n",
    "#\n",
    "# You may want try to:\n",
    "#\n",
    "#     add layers, \n",
    "#     change the number of filters per layer, \n",
    "#     use stride and various pooling layers,\n",
    "#     check the effect of using valid or same padding.\n",
    "#     ... and similarly to previous lab, you can always:       \n",
    "#     change the optimizer\n",
    "#     the learning rate,\n",
    "#     add Dropout [https://keras.io/layers/core/#dropout]\n",
    "#     add Regularisers (eg. L2, L1) [https://keras.io/regularizers/]\n",
    "#\n",
    "# Good luck!\n",
    "#\n",
    "# F.A.Q.\n",
    "#\n",
    "#   I reached 81% on my validation set, but the submission didn't pass, how come? \n",
    "#     > the test set on the server is different from your validation set\n",
    "#\n",
    "#   can I use convolutional layers? \n",
    "#     > yes, that's the whole point of this lab\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
